{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# サマースクール LLM　第3回 宿題"],"metadata":{"id":"zO6ihJbWB7H-"}},{"cell_type":"markdown","source":["## 課題\n","今回の課題は確認クイズです。\n","\n","上から回答していくとcsv提出用csv `submission_pred.csv`が作成されます。\n","提出期限までにomnicampusに提出してください。\n","\n","**採点は締め切り後に一回だけ行われます。**\n","（**即時採点ではありません。**）"],"metadata":{"id":"_peOQy2DCDIp"}},{"cell_type":"code","source":["# この部分は修正しないでください\n","import numpy as np\n","import pandas as pd\n","\n","NUM_EXAMPLE_QUESTIONS = 1\n","example = np.zeros(NUM_EXAMPLE_QUESTIONS,int)\n","\n","NUM_QUESTIONS = 5\n","myanswer = np.zeros(NUM_QUESTIONS,int)"],"metadata":{"id":"0Bv0VQqWCEF8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 回答方法\n","各$\\fbox{　(　)　}$に当てはまるものとして最も適切なものを1つずつ選んでください。\n","\n","**例題**\n","\n","「深層学習/Deep Learning応用講座 – 生成モデル」の講義では$\\fbox{　(0)　}$の技術に関して基礎的なアルゴリズムを幅広く利用可能で最先端の手法も理解し、実装することができることを目的とする。\n","\n","1. 言語モデル\n","2. 生成モデル\n","3. 強化学習\n","4. ビジネスモデル\n","\n","正しい回答を「生成モデル」とすると、以下のように0番目に2を数字で回答します．"],"metadata":{"id":"BsfoAlk8CNGt"}},{"cell_type":"markdown","source":["```python\n","example[0] = 2\n","\n","```"],"metadata":{"id":"tnPOk5rGCRFH"}},{"cell_type":"markdown","source":["### 確認クイズ\n","**Q1 言語モデルについて正しい記述を選べ**\n","\n","1. 単語の系列の生成確率をモデル化したものであり、条件付き確率によって生成も可能である\n","2. トークナイザーによる分割単位が異なったとしても、同じ文章であるなら同じ計算量で計算できる\n","3. ニューラルネットワークによって言語モデルを学習することはできない\n","4. n-gram言語モデルは直近のn+1個の単語を使って次の単語を予測する\n","\n","回答: $\\fbox{　(0)　}$\n","\n","**Q2 Transformerの特徴について正しい記述を選べ**\n","\n","1. 固定の長さの文脈を考慮した表現が得られる\n","2. RNN構造によって長距離依存性の把握ができる\n","3. 一般にAttention層とFFN層だとAttention層のパラメータが多い\n","4. Attention層とFFN層によって学習時の並列計算が効率化できたことで、学習の大規模化がしやすくなった\n","\n","回答: $\\fbox{　(1)　}$\n","\n","**Q3 Decoder-onlyと分類されるモデルは以下のうちどれか**\n","\n","1. GPT\n","2. BERT\n","3. T5\n","4. Attention is All you need論文で提案されていたモデル\n","\n","回答: $\\fbox{　(2)　}$\n","\n","**Q4 事前学習について誤っている記述はどれか**\n","1. 後続タスクのための良いパラメータの初期値が得られる、と解釈できる\n","2. 一般に大規模コーパスによる学習が必要である\n","3. 事前学習同様Next Token Predictionで学習することによってのみ後続タスクの学習を行える\n","4. 一般的に、過学習を防ぐために1~3の範囲のepoch数で学習を行う\n","\n","回答: $\\fbox{　(3)　}$\n","\n","**Q5 デコード方式について正しい記述を選べ**\n","\n","1. Random Samplingとは生起確率が1番高い次のトークンを逐一選んでいく方法である\n","2. Greedy Decodingとは高い生起確率となるようなトークン系列を探索して見つける方法である\n","3. Beam Searchとは次のトークンの生起確率分布に従いランダムに選択する方法である\n","4. どのデコード方式を用いると望む良い結果が得られるかは、タスクやモデル使用者の判断に依存する\n","\n","回答: $\\fbox{　(4)　}$\n","\n","\n","\n","\n"],"metadata":{"id":"_C3J9OjxCUCG"}},{"cell_type":"code","source":["myanswer[0] = # WRITE ME\n","myanswer[1] = # WRITE ME\n","myanswer[2] = # WRITE ME\n","myanswer[3] = # WRITE ME\n","myanswer[4] = # WRITE ME"],"metadata":{"id":"8cqW9LaPCUcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# omnicampusへ提出するcsvファイルが作成されます。\n","if not np.any(myanswer==0):\n","    submission = pd.Series(myanswer, name='label')\n","    submission.to_csv('/content/submission_pred.csv', header=True, index_label='id')\n","else:\n","    print('Error: please answer all of the questions')"],"metadata":{"id":"L3kFee09CeJM"},"execution_count":null,"outputs":[]}]}