{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GxhpPjlFEOpBJs4qrRVnb9TIJqqu6ZTO","timestamp":1694911082954}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# サマースクール LLM　第5回 宿題　クイズ"],"metadata":{"id":"zO6ihJbWB7H-"}},{"cell_type":"markdown","source":["## 課題\n","今回の課題は確認クイズです。\n","\n","上から回答していくとcsv提出用csv `submission_pred.csv`が作成されます。\n","提出期限までにomnicampusに提出してください。\n","\n","**採点は締め切り後に一回だけ行われます。**\n","（**即時採点ではありません。**）"],"metadata":{"id":"_peOQy2DCDIp"}},{"cell_type":"code","source":["# この部分は修正しないでください\n","import numpy as np\n","import pandas as pd\n","\n","NUM_EXAMPLE_QUESTIONS = 1\n","example = np.zeros(NUM_EXAMPLE_QUESTIONS,int)\n","\n","NUM_QUESTIONS = 5\n","myanswer = np.zeros(NUM_QUESTIONS,int)"],"metadata":{"id":"0Bv0VQqWCEF8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 回答方法\n","各$\\fbox{　(　)　}$に当てはまるものとして最も適切なものを1つずつ選んでください。\n","\n","**例題**\n","\n","「深層学習/Deep Learning応用講座 – 生成モデル」の講義では$\\fbox{　(0)　}$の技術に関して基礎的なアルゴリズムを幅広く利用可能で最先端の手法も理解し、実装することができることを目的とする。\n","\n","1. 言語モデル\n","2. 生成モデル\n","3. 強化学習\n","4. ビジネスモデル\n","\n","正しい回答を「生成モデル」とすると、以下のように0番目に2を数字で回答します．"],"metadata":{"id":"BsfoAlk8CNGt"}},{"cell_type":"markdown","source":["```python\n","example[0] = 2\n","\n","```"],"metadata":{"id":"tnPOk5rGCRFH"}},{"cell_type":"markdown","source":["### 確認クイズ\n","**Q1 InstructGPT論文で提案された大規模言語モデルの訓練フローに含まれない工程は、以下のうちどれ?**\n","\n","1. Pre-Training\n","2. In-Context Tuning\n","3. Supervised Fine-Tuning\n","4. Reinforcement Learning from Human Feedback\n","\n","回答: $\\fbox{　(0)　}$\n","\n","\n","**Q2 Instruction Tuningを提案したFLAN論文で報告された、Instructon Tuningの効果として最も適切なものは、以下のうちどれ?**\n","\n","1. Zero-shot性能の向上\n","2. Hallucinationの低減\n","3. 有害な出力の抑制\n","4. 多言語性能の向上\n","\n","回答: $\\fbox{　(1)　}$\n","\n","\n","**Q3 「正解ラベルを無関係なシンボルに置換したデータで Fine-Tuning し、入出力関係の学習を強制する」手法として最も適切なものは、以下のうちどれ?**\n","1. Instruction Tuning\n","2. In-Context Tuning\n","3. Symbol Tuning\n","4. Reinforcement Learning from Human Feedback\n","\n","回答: $\\fbox{　(2)　}$\n","\n","\n","**Q4 代表的なPEFT手法の内、入力文の先頭に追加したタスク固有のベクトルを学習するものは、以下のうちどれ?**\n","\n","1. Adapter\n","2. Prompt Tuning\n","3. BitFit\n","4. LoRA\n","\n","回答: $\\fbox{　(3)　}$\n","\n","\n","**Q5 各PEFT手法の説明として最も適切なものは、以下のうちどれ?**\n","\n","1. Adapterでは、Transformer構造を持つAdapterモジュールを追加・学習する\n","2. Prompt Tuningでは、Soft Promptに加えて、中間層の一部を学習する\n","3. BitFitでは、Attentionモジュールに含まれるバイアス項のみを学習する\n","4. LoRAでは、重みパラメータの学習前と学習後の差分を低ランク行列の積とし、それらの低ランク行列を学習する。\n","\n","回答: $\\fbox{　(4)　}$\n","\n","\n","\n","\n"],"metadata":{"id":"_C3J9OjxCUCG"}},{"cell_type":"code","source":["myanswer[0] = # WRITE ME\n","myanswer[1] = # WRITE ME\n","myanswer[2] = # WRITE ME\n","myanswer[3] = # WRITE ME\n","myanswer[4] = # WRITE ME"],"metadata":{"id":"8cqW9LaPCUcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# omnicampusへ提出するcsvファイルが作成されます。\n","if not np.any(myanswer==0):\n","    submission = pd.Series(myanswer, name='label')\n","    submission.to_csv('/content/submission_pred.csv', header=True, index_label='id')\n","else:\n","    print('Error: please answer all of the questions')"],"metadata":{"id":"L3kFee09CeJM"},"execution_count":null,"outputs":[]}]}