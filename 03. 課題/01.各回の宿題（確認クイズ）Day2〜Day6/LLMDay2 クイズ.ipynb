{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# サマースクール LLM　第2回 宿題"],"metadata":{"id":"zO6ihJbWB7H-"}},{"cell_type":"markdown","source":["## 課題\n","今回の課題は確認クイズです。\n","\n","上から回答していくとcsv提出用csv `submission_pred.csv`が作成されます。\n","提出期限までにomnicampusに提出してください。\n","\n","**採点は締め切り後に一回だけ行われます。**\n","（**即時採点ではありません。**）"],"metadata":{"id":"_peOQy2DCDIp"}},{"cell_type":"code","source":["# この部分は修正しないでください\n","import numpy as np\n","import pandas as pd\n","\n","NUM_EXAMPLE_QUESTIONS = 1\n","example = np.zeros(NUM_EXAMPLE_QUESTIONS,int)\n","\n","NUM_QUESTIONS = 5\n","myanswer = np.zeros(NUM_QUESTIONS,int)"],"metadata":{"id":"0Bv0VQqWCEF8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 回答方法\n","各$\\fbox{　(　)　}$に当てはまるものとして最も適切なものを1つずつ選んでください。\n","\n","**例題**\n","\n","「深層学習/Deep Learning応用講座 – 生成モデル」の講義では$\\fbox{　(0)　}$の技術に関して基礎的なアルゴリズムを幅広く利用可能で最先端の手法も理解し、実装することができることを目的とする。\n","\n","1. 言語モデル\n","2. 生成モデル\n","3. 強化学習\n","4. ビジネスモデル\n","\n","正しい回答を「生成モデル」とすると、以下のように0番目に2を数字で回答します．"],"metadata":{"id":"BsfoAlk8CNGt"}},{"cell_type":"markdown","source":["```python\n","example[0] = 2\n","\n","```"],"metadata":{"id":"tnPOk5rGCRFH"}},{"cell_type":"markdown","source":["### 確認クイズ\n","**Q1 学習済みモデルについて正しいものを選べ**\n","\n","1. 学習済みモデルとは特定のデータで学習された言語モデルである\n","2. すべての学習済みモデルはオープンソースで公開されている\n","3. 100B以上のパラメータを持つモデルも公開されている\n","4. 一般に学習済みモデルを追加学習することは禁止されている\n","\n","回答: $\\fbox{　(0)　}$\n","\n","**Q2 Promptingの説明として正しくないものを選べ**\n","\n","1. Few-Shot Promptingとは、言語モデルの入力に事例 (Demonstration) のペアを含める方法である\n","2. 言語モデルのパラメータ（重み）を劣化するように更新する方法を敵対的Promptingと呼ぶ\n","3. Promptingにおいては細かい文言の選定などの細かな要素が性能に影響する\n","4. 同じPromptingがすべてのモデルに対してうまく動作するとは限らない\n","\n","回答: $\\fbox{　(1)　}$\n","\n","**Q3 Retrieval Augmented Language Modelについて適切でない記述はどれか**\n","\n","1. モデルの学習時に得ていない新しい知識の追加や、知識の誤りを修正できることが期待される。\n","2. 一般に、NNの埋め込み表現を用いるようなDense Retrieverは重要なキーワードを含むかどうかの判定に有効で、TF-IDFのようなSparse Retrieverは文章の意味的な類似度の考慮に有効である。\n","3. 知識のデータベースをどう作るか、という観点もパイプライン設計の際に重要である。\n","4. データベースからどのように効率的に検索するか、という点に関してさまざまな研究が行われている。\n","\n","回答: $\\fbox{　(2)　}$\n","\n","**Q4 Tool Augmented Language Modelについて適切でない記述はどれか**\n","1. ツールの利用で計算が正確に行えたりAPIの利用ができ、モデル単体よりも複雑なタスクを解くことが期待される。\n","2. ツールの利用する際はLLMの出力をAPIのインターフェースに合うように出力するなどして利用することができる。\n","3. ツールの利用の際にはfew-shot / CoT promptingなどのプロンプトの工夫も活用することができる。\n","4. ツールの利用を促すような学習をすることはできない。\n","\n","回答: $\\fbox{　(3)　}$\n","\n","**Q5 各手法の説明として正しいものを選べ**\n","\n","1. Self-Consistencyとは、一般に外部の文章との整合性を確認することを指す\n","2. Chain-of-Thoughtsとは、一般に推論能力を高めるように追加学習することを指す\n","3. REPLUGは、検索した文章をコンテキストとして入力することで予測を修正するRetrieval Augmented LMの手法の1つである\n","4. Chameleonは、Web操作を主眼としたTool Augmented LMで、文章検索などは出来ない\n","\n","回答: $\\fbox{　(4)　}$\n","\n","\n","\n","\n"],"metadata":{"id":"_C3J9OjxCUCG"}},{"cell_type":"code","source":["myanswer[0] = # WRITE ME\n","myanswer[1] = # WRITE ME\n","myanswer[2] = # WRITE ME\n","myanswer[3] = # WRITE ME\n","myanswer[4] = # WRITE ME"],"metadata":{"id":"8cqW9LaPCUcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# omnicampusへ提出するcsvファイルが作成されます。\n","if not np.any(myanswer==0):\n","    submission = pd.Series(myanswer, name='label')\n","    submission.to_csv('/content/submission_pred.csv', header=True, index_label='id')\n","else:\n","    print('Error: please answer all of the questions')"],"metadata":{"id":"L3kFee09CeJM"},"execution_count":null,"outputs":[]}]}